{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Author:** Sergey Morozov  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTICE\n",
    "\n",
    "Some of the functions below were provided by [Udacity](https://www.udacity.com/). Author modified some of them and added original code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Steps\n",
    "- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier.\n",
    "- Apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "- Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "- Run pipeline on a video stream and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "- Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Extraction\n",
    "\n",
    "Archive with vehicle and non-vehicle images should be manually downloaded and placed in the root of this repository.\n",
    "- [vehicles.zip](https://yadi.sk/d/z55uKF-J3KNDgg)\n",
    "- [non-vehicles.zip](https://yadi.sk/d/-blY05xV3KNDnV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Extract vehicle images\n",
    "if not (os.path.isdir(\"vehicle_images\")):\n",
    "    zip_ref = zipfile.ZipFile(\"vehicles.zip\", 'r')\n",
    "    zip_ref.extractall(\".\")\n",
    "    zip_ref.close()\n",
    "    shutil.move(\"vehicles\", \"vehicle_images\")\n",
    "    shutil.rmtree(\"__MACOSX\")\n",
    "    \n",
    "# Extract non-vehicle images\n",
    "if not (os.path.isdir(\"non-vehicle_images\")):\n",
    "    zip_ref = zipfile.ZipFile(\"non-vehicles.zip\", 'r')\n",
    "    zip_ref.extractall(\".\")\n",
    "    zip_ref.close()\n",
    "    shutil.move(\"non-vehicles\", \"non-vehicle_images\")\n",
    "    shutil.rmtree(\"__MACOSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def data_look(car_list, notcar_list):\n",
    "    \"\"\"Extract useful information about provided data.\"\"\"\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = cv2.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "\n",
    "# List containing paths to training images\n",
    "vehicle_paths = glob.glob(\"vehicle_images/*/*.png\")\n",
    "nonvehicle_paths = glob.glob(\"non-vehicle_images/*/*.png\")\n",
    "\n",
    "# Extract useful information from data\n",
    "data_info = data_look(vehicle_paths, nonvehicle_paths)\n",
    "\n",
    "# Define useful constants\n",
    "cars_cnt = data_info['n_cars']\n",
    "notcars_cnt = data_info['n_notcars']\n",
    "image_shape = data_info['image_shape']\n",
    "data_type = data_info['data_type']\n",
    "\n",
    "# Print extracted information\n",
    "print(\"Vehicle image count:\", cars_cnt)\n",
    "print(\"Non-vehicle image count:\", notcars_cnt)\n",
    "print(\"Image shape:\", image_shape)\n",
    "print(\"Image type:\", data_type)\n",
    "\n",
    "# Show example images from each category\n",
    "fig, axs = plt.subplots(1,8, figsize=(16, 2))\n",
    "\n",
    "for i in range(4):\n",
    "    img = mpimg.imread(vehicle_paths[i * i * 3])\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('Vehicle')\n",
    "    axs[i].imshow(img)\n",
    "    \n",
    "for i in range(4,8):\n",
    "    img = mpimg.imread(nonvehicle_paths[i * i * 3])\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('Non-Vehicle')\n",
    "    axs[i].imshow(img)\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "\n",
    "plt.savefig('output_images/data_examples.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256), features_only=True):\n",
    "    \"\"\"Function to compute color histogram features.\"\"\"\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    if features_only:\n",
    "        return hist_features\n",
    "    else:\n",
    "        # Generating bin centers\n",
    "        bin_edges = channel1_hist[1]\n",
    "        bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "        return channel1_hist, channel2_hist, channel3_hist, bin_centers, hist_features\n",
    "\n",
    "# Draw historgam for each color channel\n",
    "# As an example consider BGR color space    \n",
    "fig, axs = plt.subplots(2,4, figsize=(16, 6))\n",
    "\n",
    "# Draw histograms for vehicle\n",
    "vehicle_img = cv2.imread(vehicle_paths[0])\n",
    "nonvehicle_img = cv2.imread(nonvehicle_paths[0])\n",
    "imgs_for_hist = [(vehicle_paths[0], \"Vehicle\"), (nonvehicle_paths[0], \"Non-Vehicle\")]\n",
    "\n",
    "for i in range(2):\n",
    "    image = cv2.imread(imgs_for_hist[i][0])\n",
    "    ch1_hist, ch2_hist, ch3_hist, bincen, feature_vec = \\\n",
    "        color_hist(image, nbins=32, bins_range=(0, 256), features_only=False)\n",
    "    axs[i][0].axis('off')\n",
    "    axs[i][0].set_title(imgs_for_hist[i][1])\n",
    "    axs[i][0].imshow(image)\n",
    "    axs[i][1].bar(bincen, ch1_hist[0])\n",
    "    axs[i][1].set_xlim([0, 256])\n",
    "    axs[i][1].set_title('B Histogram')\n",
    "    axs[i][2].bar(bincen, ch2_hist[0])\n",
    "    axs[i][2].set_xlim([0, 256])\n",
    "    axs[i][2].set_title('G Histogram')\n",
    "    axs[i][3].bar(bincen, ch3_hist[0])\n",
    "    axs[i][3].set_xlim([0, 256])\n",
    "    axs[i][3].set_title('R Histogram')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "\n",
    "plt.savefig('output_images/histogram_of_color.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "def plot3d(pixels, colors_rgb, fig, pos,\n",
    "           axis_labels=list(\"RGB\"), \n",
    "           axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # 3D axes\n",
    "    ax = fig.add_subplot(pos, projection='3d')\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=7, pad=1)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=10, labelpad=1)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=10, labelpad=1)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=10, labelpad=1)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "# Read a color image\n",
    "img = cv2.imread(\"test_images/test4.jpg\")\n",
    "\n",
    "# Select a small fraction of pixels to plot by subsampling it\n",
    "scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Convert subsampled image to desired color space(s)\n",
    "img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_small_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "img_small_LUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "img_small_YUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2YUV)\n",
    "img_small_YCrCb = cv2.cvtColor(img_small, cv2.COLOR_BGR2YCrCb)\n",
    "img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "# Plot and show\n",
    "ax = fig.add_subplot(332)\n",
    "ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "ax.axis(\"off\")\n",
    "plot3d(img_small_RGB, img_small_rgb, fig, 334)\n",
    "plot3d(img_small_HSV, img_small_rgb, fig, 335, axis_labels=list(\"HSV\"))\n",
    "plot3d(img_small_HLS, img_small_rgb, fig, 336, axis_labels=list(\"HLS\"))\n",
    "plot3d(img_small_LUV, img_small_rgb, fig, 337, axis_labels=list(\"LUV\"))\n",
    "plot3d(img_small_YUV, img_small_rgb, fig, 338, axis_labels=list(\"YUV\"))\n",
    "plot3d(img_small_YCrCb, img_small_rgb, fig, 339, axis_labels=['Y', 'Cr', 'Cb'])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/color_distribution.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Binning of Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    \"\"\"Function to compute binned color features.\"\"\"\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Read test image\n",
    "img = cv2.imread(\"test_images/test4.jpg\")\n",
    "\n",
    "# Convert subsampled image to desired color space(s)\n",
    "img_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "img_LUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "img_YUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2YUV)\n",
    "img_YCrCb = cv2.cvtColor(img_small, cv2.COLOR_BGR2YCrCb)\n",
    "  \n",
    "fig, axs = plt.subplots(2,3, figsize=(16, 6))\n",
    "\n",
    "axs[0][0].plot(bin_spatial(img_RGB))\n",
    "axs[0][0].set_title('RGB')\n",
    "\n",
    "axs[0][1].plot(bin_spatial(img_HSV))\n",
    "axs[0][1].set_title('HSV')\n",
    "\n",
    "axs[0][2].plot(bin_spatial(img_HLS))\n",
    "axs[0][2].set_title('HLS')\n",
    "\n",
    "axs[1][0].plot(bin_spatial(img_LUV))\n",
    "axs[1][0].set_title('LUV')\n",
    "\n",
    "axs[1][1].plot(bin_spatial(img_YUV))\n",
    "axs[1][1].set_title('YUV')\n",
    "\n",
    "axs[1][2].plot(bin_spatial(img_YCrCb))\n",
    "axs[1][2].set_title('YCrCb')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/spatial_binning.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Oriented Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    \"\"\"Function to return HOG features and visualization.\"\"\"\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "# Read in the image\n",
    "image = cv2.imread(vehicle_paths[123])\n",
    "img_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "img_HLS = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "img_LUV = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "img_YUV = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "imgs = [(img_RGB, list(\"RGB\")), \n",
    "        (img_HSV, list(\"HSV\")), \n",
    "        (img_HLS, list(\"HSL\")), \n",
    "        (img_LUV, list(\"LUV\")), \n",
    "        (img_YUV, list(\"YUV\")), \n",
    "        (img_YCrCb, ['Y', 'Cr', 'Cb'])]\n",
    "\n",
    "# Define HOG parameters\n",
    "orient = 12\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 1\n",
    "\n",
    "fig = plt.figure(figsize=(32,32))\n",
    "\n",
    "ax = fig.add_subplot(732)\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(image)\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    pos = (i + 1) * 3 + 1\n",
    "    features, hog_image = get_hog_features(imgs[i][0][:,:,0], orient, \n",
    "                                           pix_per_cell, cell_per_block, \n",
    "                                           vis=True, feature_vec=False)\n",
    "    ax = fig.add_subplot(7, 3, pos)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(hog_image, cmap='gray')\n",
    "    ax.set_title(imgs[i][1][0])\n",
    "    \n",
    "    pos += 1\n",
    "    features, hog_image = get_hog_features(imgs[i][0][:,:,1], orient, \n",
    "                                           pix_per_cell, cell_per_block, \n",
    "                                           vis=True, feature_vec=False)\n",
    "    ax = fig.add_subplot(7, 3, pos)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(hog_image, cmap='gray')\n",
    "    ax.set_title(imgs[i][1][1])\n",
    "    \n",
    "    pos += 1\n",
    "    features, hog_image = get_hog_features(imgs[i][0][:,:,2], orient, \n",
    "                                           pix_per_cell, cell_per_block, \n",
    "                                           vis=True, feature_vec=False)\n",
    "    ax = fig.add_subplot(7, 3, pos)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(hog_image, cmap='gray')\n",
    "    ax.set_title(imgs[i][1][2])\n",
    "    \n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/hog.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Linear Support Vector Machine Classifier\n",
    "\n",
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be tweaked\n",
    "color_space = 'HLS' # Can be BGR, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 12\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 64    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "bins_range=(0,256)\n",
    "\n",
    "print('Parameters were defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Features and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# The next step is quite long. You load scaler from the file system.\n",
    "#####\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the scaler\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    X_scaler = pickle.load(file)    \n",
    "    print('Scaler was loaded from file', file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "def extract_features(imgs, color_space='BGR', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \"\"\"Function to extract features from a list of images.\n",
    "    \n",
    "    This function calls bin_spatial(), color_hist(), and get_hog_features().\n",
    "    \"\"\"\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = cv2.imread(file)\n",
    "        # apply color conversion if other than 'BGR'\n",
    "        if color_space != 'BGR':\n",
    "            if color_space == 'RGB':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "car_features = extract_features(vehicle_paths, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(nonvehicle_paths, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "# Normalize data\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# save the scaler\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(X_scaler, file)    \n",
    "    print('Scaler was saved to', file.name)\n",
    "\n",
    "# Visualize normalization\n",
    "car_ind = 28\n",
    "# Plot an example of raw and scaled features\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(mpimg.imread(vehicle_paths[car_ind]))\n",
    "plt.title('Original Image')\n",
    "plt.subplot(132)\n",
    "plt.plot(X[car_ind])\n",
    "plt.title('Raw Features')\n",
    "plt.subplot(133)\n",
    "plt.plot(scaled_X[car_ind])\n",
    "plt.title('Normalized Features')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/feature_normalization.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# The next step is quite long. You load support vector classifier from the file system.\n",
    "#####\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the classifier\n",
    "with open('svc.pkl', 'rb') as file:\n",
    "    svc = pickle.load(file)    \n",
    "    print('Classifier was loaded from file', file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "\n",
    "# save the trained classifier\n",
    "with open('svc.pkl', 'wb') as file:\n",
    "    pickle.dump(svc, file)    \n",
    "    print('Classifier was saved to', file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    \"\"\"Function that returns a list of bounding boxes for the search windows.\"\"\"\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    \"\"\"Function that draws color boxes on the output.\"\"\"\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "# Visualize the result\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "img_cnt = 1\n",
    "for name in os.listdir(\"test_images\"):\n",
    "    # Read test image\n",
    "    image = cv2.imread(os.path.join(\"test_images\", name))\n",
    "\n",
    "    windows = slide_window(image, x_start_stop=[None, None], y_start_stop=[400, 700], \n",
    "                           xy_window=(128, 128), xy_overlap=(0.5, 0.5))\n",
    "                       \n",
    "    window_img = draw_boxes(image, windows, color=(0, 0, 255), thick=6)                    \n",
    "    \n",
    "    ax = fig.add_subplot(3, 2, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/sliding_window.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search and Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def single_img_features(img, color_space='BGR', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    \"\"\"Function to extract features from a single image window.\"\"\"\n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'BGR'\n",
    "    if color_space != 'BGR':\n",
    "        if color_space == 'RGB':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "def search_windows(img, windows, clf, scaler, color_space='BGR', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "    \"\"\"Search cars in the given image within list of windows to be searched.\"\"\"\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "y_start_stop = [400, 700] # Min and max in y to search in slide_window()\n",
    "\n",
    "# Visualize the result\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "times = []\n",
    "\n",
    "img_cnt = 1\n",
    "for name in os.listdir(\"test_images\"):\n",
    "    # Read test image\n",
    "    image = cv2.imread(os.path.join(\"test_images\", name))\n",
    "\n",
    "    draw_image = np.copy(image)\n",
    "    \n",
    "    tm_start = time.time()\n",
    "\n",
    "    windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                           xy_window=(115, 115), xy_overlap=(0.8, 0.8))\n",
    "\n",
    "    hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                                 spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                 orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                 cell_per_block=cell_per_block, \n",
    "                                 hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                 hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "    window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6) \n",
    "    \n",
    "    tm_stop = time.time()\n",
    "    \n",
    "    times.append(round(tm_stop-tm_start, 2))\n",
    "    \n",
    "    ax = fig.add_subplot(6, 2, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "    \n",
    "    ax = fig.add_subplot(6, 2, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "print(\"Average time per image:\", sum(times)/len(times), \"sec\")\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/search_and_classify.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection is quite good, but very slow. It can not be used in real time systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faster Search (HOG Sub-Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "def find_cars(img, ystart, ystop, scale, clf, X_scaler, \n",
    "              orient, pix_per_cell, cell_per_block, spatial_size, \n",
    "              hist_bins, color_space, bins_range):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    \n",
    "    if color_space != 'BGR':\n",
    "        if color_space == 'RGB':\n",
    "            img_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2RGB)\n",
    "        if color_space == 'HSV':\n",
    "            img_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            img_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            img_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            img_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            img_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_BGR2YCrCb)\n",
    "    else: img_tosearch = np.copy(img_tosearch) \n",
    "    \n",
    "    if scale != 1:\n",
    "        imshape = img_tosearch.shape\n",
    "        img_tosearch = cv2.resize(img_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "    \n",
    "    ch1 = img_tosearch[:,:,0]\n",
    "    ch2 = img_tosearch[:,:,1]\n",
    "    ch3 = img_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = image_shape[0]\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    bbox_list=[]\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(img_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins, bins_range=bins_range)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features,\n",
    "                                                          hog_features)).reshape(1, -1))       \n",
    "            test_prediction = clf.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),\n",
    "                              (xbox_left+win_draw,ytop_draw+win_draw+ystart),\n",
    "                              (0,0,1),6)\n",
    "                bbox_list.append(((xbox_left, ytop_draw+ystart),\n",
    "                              (xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "    return bbox_list\n",
    "\n",
    "y_start_stop = [400, 700]\n",
    "\n",
    "# Visualize the result\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "times = []\n",
    "\n",
    "img_cnt = 1\n",
    "for name in os.listdir(\"test_images\"):\n",
    "    # Read test image\n",
    "    image = cv2.imread(os.path.join(\"test_images\", name))\n",
    "\n",
    "    draw_image = np.copy(image)\n",
    "    \n",
    "    tm_start = time.time()\n",
    "\n",
    "    bbox_list = find_cars(image, y_start_stop[0], y_start_stop[1], 1, svc, X_scaler, \n",
    "                          orient, pix_per_cell, cell_per_block, spatial_size,\n",
    "                          hist_bins, color_space, bins_range)\n",
    "    draw_image = draw_boxes(draw_image, bbox_list)\n",
    "    \n",
    "    tm_stop = time.time()\n",
    "    \n",
    "    times.append(round(tm_stop-tm_start, 2))\n",
    "    \n",
    "    ax = fig.add_subplot(6, 2, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "    \n",
    "    ax = fig.add_subplot(6, 2, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(draw_image, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "print(\"Average time per image:\", sum(times)/len(times), \"sec\")\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/fast_search_and_classify.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection is quite good and fast enough. On a very-very good laptop it can process video in near real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "y_start_stop = [400, 700] # Min and max in y to search in slide_window()\n",
    "\n",
    "# Visualize the result\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "img_cnt = 1\n",
    "for name in os.listdir(\"test_images\"):\n",
    "    # Read test image\n",
    "    image = cv2.imread(os.path.join(\"test_images\", name))\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "    draw_image = np.copy(image)\n",
    "    \n",
    "    bbox_list = find_cars(image, y_start_stop[0], y_start_stop[1], 1, svc, X_scaler, \n",
    "                          orient, pix_per_cell, cell_per_block, spatial_size,\n",
    "                          hist_bins, color_space, bins_range)\n",
    "    draw_image = draw_boxes(draw_image, bbox_list)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,bbox_list)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,1)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    \n",
    "    ax = fig.add_subplot(6, 3, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "    \n",
    "    ax = fig.add_subplot(6, 3, img_cnt)\n",
    "    ax.imshow(heatmap, cmap='hot')\n",
    "    img_cnt += 1\n",
    "    \n",
    "    ax = fig.add_subplot(6, 3, img_cnt)\n",
    "    ax.imshow(cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB))\n",
    "    img_cnt += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Create directory where to save output images\n",
    "if not os.path.isdir(\"output_images\"):\n",
    "    os.mkdir(\"output_images\")\n",
    "    \n",
    "plt.savefig('output_images/heat_map.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTICE:* ideas related to vehicle tracking, such as remembering bboxes identified in previous N frames, were borrowed from Prerit Jaiswal's [repository](https://github.com/preritj/Vechicle-Detection-Tracking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "class VehicleDetector:\n",
    "    def __init__(self, n_iter=25, n_update=2, threshold=70, \n",
    "                 scale_yrange_map={0.8 : (380,500),\n",
    "                                   1.0 : (380,550), \n",
    "                                   1.5 : (380,580), \n",
    "                                   2.0 : (380,650), \n",
    "                                   2.5 : (380,700)}):\n",
    "        # Number of processed frames\n",
    "        self.count = 0\n",
    "        \n",
    "        # Labeled bboxes \n",
    "        self.out_img_labeled = None\n",
    "        \n",
    "        # Vehicle labels \n",
    "        self.labels = [None,0]\n",
    "        \n",
    "        # List of bbox lists from last n iterations\n",
    "        self.bbox_list_n = [] \n",
    "        \n",
    "        # Number of frames to smooth over\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "        # Number of frames after which to update detection\n",
    "        self.n_update = n_update\n",
    "        \n",
    "        # Threshold for heat map\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Heat map\n",
    "        self.heat = np.zeros((720, 1280))\n",
    "        self.heatmap = np.copy(self.heat)\n",
    "        \n",
    "        # Map scale to y range\n",
    "        self.scale_yrange_map = scale_yrange_map\n",
    "    \n",
    "    def pipeline(self, image) :\n",
    "        # Increment number of processed frames\n",
    "        self.count += 1\n",
    "        \n",
    "        # Image to be processed\n",
    "        self.image = image\n",
    "\n",
    "        # Frames are RGB, while the rest of the code works with BGR\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Find cars of the processed frame\n",
    "        for scale, y_start_stop in self.scale_yrange_map.items():\n",
    "            ystart = y_start_stop[0]\n",
    "            ystop  = y_start_stop[1]\n",
    "            bbox_list = find_cars(img, ystart, ystop, scale, svc, X_scaler, \n",
    "                              orient, pix_per_cell, cell_per_block, spatial_size,\n",
    "                              hist_bins, color_space, bins_range)\n",
    "        \n",
    "        # Add found car boxes to the list of boxes captured in N previous frames\n",
    "        self.bbox_list_n.append(bbox_list)\n",
    "        \n",
    "        # Update heat map each self.n_update frame (smoothing)\n",
    "        if self.count % self.n_update == 0 :\n",
    "            for bbox_list in self.bbox_list_n :\n",
    "                self.heat = add_heat(self.heat,bbox_list)\n",
    "            self.heat = apply_threshold(self.heat, self.threshold)\n",
    "            self.heatmap = np.clip(self.heat, 0, 255)\n",
    "            self.labels = label(self.heatmap)\n",
    "            self.heat = np.clip(self.labels[0], 0, 1) * 2\n",
    "        \n",
    "        # Remove very old cars boxes\n",
    "        if len(self.bbox_list_n) > self.n_iter :\n",
    "            self.bbox_list_n.pop(0)\n",
    "            \n",
    "        # Draw labeled boxes on the image being processed\n",
    "        self.out_img_labeled = draw_labeled_bboxes(np.copy(image), self.labels)\n",
    "        return self.out_img_labeled\n",
    "    \n",
    "# Create output directory for vidoes, if does not exist\n",
    "if not os.path.isdir(\"output_videos\"):\n",
    "        os.mkdir(\"output_videos\")\n",
    "\n",
    "# Define paths to source and destination videos\n",
    "vid_src = \"test_videos/test_video.mp4\"\n",
    "vid_dst = \"output_videos/test_video.mp4\"\n",
    "\n",
    "# Process video frame by frame\n",
    "video = VideoFileClip(vid_src)\n",
    "video_clip = video.fl_image(VehicleDetector().pipeline)\n",
    "%time video_clip.write_videofile(vid_dst, audio = False)\n",
    "display(HTML(\n",
    "        \"\"\"\n",
    "            <video width=\"960\" height=\"540\" controls>\n",
    "               <source src=\"{0}\">\n",
    "            </video>\n",
    "        \"\"\".format(vid_dst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Pipeline to Long Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "# Create output directory for vidoes, if does not exist\n",
    "if not os.path.isdir(\"output_videos\"):\n",
    "        os.mkdir(\"output_videos\")\n",
    "\n",
    "# Define paths to source and destination videos\n",
    "vid_src = \"test_videos/project_video.mp4\"\n",
    "vid_dst = \"output_videos/project_video.mp4\"\n",
    "\n",
    "# Process video frame by frame\n",
    "video = VideoFileClip(vid_src)\n",
    "video_clip = video.fl_image(VehicleDetector().pipeline)\n",
    "%time video_clip.write_videofile(vid_dst, audio = False)\n",
    "display(HTML(\n",
    "        \"\"\"\n",
    "            <video width=\"960\" height=\"540\" controls>\n",
    "               <source src=\"{0}\">\n",
    "            </video>\n",
    "        \"\"\".format(vid_dst)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
